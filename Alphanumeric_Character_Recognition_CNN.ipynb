{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j_3eIJ-n3GTX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"amansachan0525\"\n",
        "os.environ['KAGGLE_KEY'] = \"f7f5902fb7627990cdc80e648f2b798a\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf5WACu5-8Lg",
        "outputId": "9bb0f8da-1f52-48a9-be9a-de78c43b7227"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'kaggle' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "tar: Error opening archive: Failed to open 'EnglishFnt.tgz'\n",
            "tar: Error opening archive: Failed to open 'EnglishImg.tgz'\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d passionoflife/english-typed-alphabets-and-numbers-dataset --unzip\n",
        "!tar -xvzf EnglishFnt.tgz\n",
        "!tar -xvzf EnglishImg.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j8wFRXqXdvi",
        "outputId": "f93f8c65-27c8-42ac-d72f-eb0c6b37e0b0"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 3] The system cannot find the path specified: '/content/English/Img/BadImag/Bmp/'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Aman\\Car-Nameplate-Character-Recognition-CNN\\Alphanumeric_Character_Recognition_CNN.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aman/Car-Nameplate-Character-Recognition-CNN/Alphanumeric_Character_Recognition_CNN.ipynb#ch0000002?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mos\u001b[39;00m \u001b[39mimport\u001b[39;00m listdir\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Aman/Car-Nameplate-Character-Recognition-CNN/Alphanumeric_Character_Recognition_CNN.ipynb#ch0000002?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m listdir(\u001b[39m'\u001b[39;49m\u001b[39m/content/English/Img/BadImag/Bmp/\u001b[39;49m\u001b[39m'\u001b[39;49m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aman/Car-Nameplate-Character-Recognition-CNN/Alphanumeric_Character_Recognition_CNN.ipynb#ch0000002?line=2'>3</a>\u001b[0m   filename \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(f[\u001b[39m7\u001b[39m:\u001b[39m9\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aman/Car-Nameplate-Character-Recognition-CNN/Alphanumeric_Character_Recognition_CNN.ipynb#ch0000002?line=3'>4</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mint\u001b[39m(filename))\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/English/Img/BadImag/Bmp/'"
          ]
        }
      ],
      "source": [
        "from os import listdir\n",
        "for f in listdir('/content/English/Img/BadImag/Bmp/'):\n",
        "  filename = str(f[7:9])\n",
        "  print(int(filename))\n",
        "  if int(filename) >= 37:\n",
        "    path = '/content/English/Img/BadImag/Bmp/'+f\n",
        "    print(path)\n",
        "    !rm -rf $path\n",
        "\n",
        "for f in listdir('/content/English/Img/GoodImg/Bmp/'):\n",
        "  filename = str(f[7:9])\n",
        "  print(int(filename))\n",
        "  if int(filename) >= 37:\n",
        "    path = '/content/English/Img/GoodImg/Bmp/'+f\n",
        "    print(path)\n",
        "    !rm -rf $path\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0eRgUI9Bs_I",
        "outputId": "0f43e9b6-6b41-47f4-b649-8a501a4a94ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5795 images belonging to 36 classes.\n",
            "Found 3358 images belonging to 36 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 64)        129856    \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 14400)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1843328   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 36)                4644      \n",
            "=================================================================\n",
            "Total params: 1,977,828\n",
            "Trainable params: 1,977,828\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5795/5795 [==============================] - 218s 37ms/step - loss: 3.3294 - accuracy: 0.0932 - val_loss: 3.2314 - val_accuracy: 0.1087\n",
            "Epoch 2/100\n",
            "5795/5795 [==============================] - 216s 37ms/step - loss: 3.1935 - accuracy: 0.1506 - val_loss: 3.1014 - val_accuracy: 0.1438\n",
            "Epoch 3/100\n",
            "5795/5795 [==============================] - 216s 37ms/step - loss: 2.9022 - accuracy: 0.2939 - val_loss: 2.8660 - val_accuracy: 0.2808\n",
            "Epoch 4/100\n",
            "5795/5795 [==============================] - 216s 37ms/step - loss: 2.5193 - accuracy: 0.4121 - val_loss: 2.6406 - val_accuracy: 0.3562\n",
            "Epoch 5/100\n",
            "5795/5795 [==============================] - 216s 37ms/step - loss: 2.1804 - accuracy: 0.4959 - val_loss: 2.4184 - val_accuracy: 0.4127\n",
            "Epoch 6/100\n",
            "5795/5795 [==============================] - 218s 38ms/step - loss: 1.9203 - accuracy: 0.5538 - val_loss: 2.2721 - val_accuracy: 0.4553\n",
            "Epoch 7/100\n",
            "5795/5795 [==============================] - 220s 38ms/step - loss: 1.7075 - accuracy: 0.6016 - val_loss: 2.1146 - val_accuracy: 0.4952\n",
            "Epoch 8/100\n",
            "5795/5795 [==============================] - 218s 38ms/step - loss: 1.5250 - accuracy: 0.6342 - val_loss: 2.1054 - val_accuracy: 0.4726\n",
            "Epoch 9/100\n",
            "5795/5795 [==============================] - 218s 38ms/step - loss: 1.3706 - accuracy: 0.6683 - val_loss: 2.0163 - val_accuracy: 0.5039\n",
            "Epoch 10/100\n",
            "5795/5795 [==============================] - 221s 38ms/step - loss: 1.2583 - accuracy: 0.6932 - val_loss: 1.8935 - val_accuracy: 0.5241\n",
            "Epoch 11/100\n",
            "5795/5795 [==============================] - 219s 38ms/step - loss: 1.1638 - accuracy: 0.7163 - val_loss: 1.8587 - val_accuracy: 0.5447\n",
            "Epoch 12/100\n",
            "5795/5795 [==============================] - 219s 38ms/step - loss: 1.0868 - accuracy: 0.7298 - val_loss: 1.7957 - val_accuracy: 0.5625\n",
            "Epoch 13/100\n",
            "5795/5795 [==============================] - 219s 38ms/step - loss: 1.0216 - accuracy: 0.7451 - val_loss: 1.7706 - val_accuracy: 0.5560\n",
            "Epoch 14/100\n",
            "5795/5795 [==============================] - 219s 38ms/step - loss: 0.9598 - accuracy: 0.7601 - val_loss: 1.7105 - val_accuracy: 0.5673\n",
            "Epoch 15/100\n",
            "5795/5795 [==============================] - 221s 38ms/step - loss: 0.9125 - accuracy: 0.7755 - val_loss: 1.6769 - val_accuracy: 0.5899\n",
            "Epoch 16/100\n",
            "5795/5795 [==============================] - 220s 38ms/step - loss: 0.8635 - accuracy: 0.7807 - val_loss: 1.7102 - val_accuracy: 0.5783\n",
            "Epoch 17/100\n",
            "5795/5795 [==============================] - 221s 38ms/step - loss: 0.8301 - accuracy: 0.7907 - val_loss: 1.6856 - val_accuracy: 0.5881\n",
            "Epoch 18/100\n",
            "5795/5795 [==============================] - 221s 38ms/step - loss: 0.7895 - accuracy: 0.7955 - val_loss: 1.6536 - val_accuracy: 0.5828\n",
            "Epoch 19/100\n",
            "5795/5795 [==============================] - 221s 38ms/step - loss: 0.7543 - accuracy: 0.8086 - val_loss: 1.6751 - val_accuracy: 0.5893\n",
            "Epoch 20/100\n",
            "5795/5795 [==============================] - 220s 38ms/step - loss: 0.7375 - accuracy: 0.8091 - val_loss: 1.6815 - val_accuracy: 0.5795\n",
            "Epoch 21/100\n",
            "5795/5795 [==============================] - 219s 38ms/step - loss: 0.7039 - accuracy: 0.8233 - val_loss: 1.6029 - val_accuracy: 0.6069\n",
            "Epoch 22/100\n",
            "5795/5795 [==============================] - 221s 38ms/step - loss: 0.6842 - accuracy: 0.8312 - val_loss: 1.6503 - val_accuracy: 0.5914\n",
            "Epoch 23/100\n",
            "5795/5795 [==============================] - 220s 38ms/step - loss: 0.6714 - accuracy: 0.8255 - val_loss: 1.6226 - val_accuracy: 0.6033\n",
            "Epoch 24/100\n",
            "5795/5795 [==============================] - 221s 38ms/step - loss: 0.6390 - accuracy: 0.8347 - val_loss: 1.4987 - val_accuracy: 0.6313\n",
            "Epoch 25/100\n",
            "5795/5795 [==============================] - 220s 38ms/step - loss: 0.6314 - accuracy: 0.8368 - val_loss: 1.6124 - val_accuracy: 0.6102\n",
            "Epoch 26/100\n",
            "5795/5795 [==============================] - 221s 38ms/step - loss: 0.6156 - accuracy: 0.8428 - val_loss: 1.5302 - val_accuracy: 0.6248\n",
            "Epoch 27/100\n",
            "5795/5795 [==============================] - 220s 38ms/step - loss: 0.5969 - accuracy: 0.8483 - val_loss: 1.5754 - val_accuracy: 0.6164\n",
            "Epoch 28/100\n",
            "5795/5795 [==============================] - 221s 38ms/step - loss: 0.5705 - accuracy: 0.8545 - val_loss: 1.5765 - val_accuracy: 0.6176\n",
            "Epoch 29/100\n",
            "5795/5795 [==============================] - 220s 38ms/step - loss: 0.5599 - accuracy: 0.8531 - val_loss: 1.4691 - val_accuracy: 0.6474\n",
            "Epoch 30/100\n",
            "5795/5795 [==============================] - 213s 37ms/step - loss: 0.5530 - accuracy: 0.8542 - val_loss: 1.6829 - val_accuracy: 0.6007\n",
            "Epoch 31/100\n",
            "5795/5795 [==============================] - 212s 37ms/step - loss: 0.5276 - accuracy: 0.8623 - val_loss: 1.4601 - val_accuracy: 0.6557\n",
            "Epoch 32/100\n",
            "5795/5795 [==============================] - 215s 37ms/step - loss: 0.5170 - accuracy: 0.8614 - val_loss: 1.4991 - val_accuracy: 0.6557\n",
            "Epoch 33/100\n",
            "5795/5795 [==============================] - 213s 37ms/step - loss: 0.5031 - accuracy: 0.8689 - val_loss: 1.5619 - val_accuracy: 0.6266\n",
            "Epoch 34/100\n",
            "5795/5795 [==============================] - 213s 37ms/step - loss: 0.4996 - accuracy: 0.8701 - val_loss: 1.5671 - val_accuracy: 0.6275\n",
            "Epoch 35/100\n",
            "5795/5795 [==============================] - 212s 37ms/step - loss: 0.4733 - accuracy: 0.8758 - val_loss: 1.5096 - val_accuracy: 0.6495\n",
            "Epoch 36/100\n",
            "5795/5795 [==============================] - 213s 37ms/step - loss: 0.4688 - accuracy: 0.8782 - val_loss: 1.5001 - val_accuracy: 0.6501\n",
            "Epoch 37/100\n",
            "5795/5795 [==============================] - 213s 37ms/step - loss: 0.4600 - accuracy: 0.8751 - val_loss: 1.5086 - val_accuracy: 0.6513\n",
            "Epoch 38/100\n",
            " 487/5795 [=>............................] - ETA: 2:42 - loss: 0.4809 - accuracy: 0.8439"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "# loading training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "         width_shift_range=0.1, \n",
        "         height_shift_range=0.1)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/English/Img/GoodImg/Bmp',\n",
        "        target_size=(30, 30),\n",
        "        batch_size=1,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# loading testing data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "        '/content/English/Img/BadImag/Bmp',\n",
        "        target_size=(30, 30),\n",
        "        batch_size=1,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# initialising sequential model and adding layers to it\n",
        "cnn = tf.keras.models.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(26,26), activation='relu', input_shape=(30, 30, 3), padding='same',))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(36, activation='softmax'))\n",
        "cnn.summary()\n",
        "# finally compile and train the cnn\n",
        "cnn.compile(optimizer=Adam(learning_rate=0.00001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "cnn.fit(x=train_generator, validation_data=test_generator, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB-lYvR7SPWK"
      },
      "outputs": [],
      "source": [
        "cnn.save(\"AlphaNumericCharacterRecognition.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Alphanumeric-Character-Recognition-CNN.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
